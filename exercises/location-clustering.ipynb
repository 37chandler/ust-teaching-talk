{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location-Based Market Clustering\n",
    "\n",
    "This exercise builds on our initial market comparison work. Instead of building individual models for each location, we'll use clustering to group similar markets together and build models for each cluster.\n",
    "\n",
    "### Our Goals:\n",
    "1. Understand what makes markets similar\n",
    "2. Use clustering to group markets effectively\n",
    "3. Balance model accuracy with market coverage\n",
    "4. Compare cluster-based models to national models\n",
    "\n",
    "### Key Steps:\n",
    "1. Compare locations across different dimensions\n",
    "2. Choose a representative make/model\n",
    "3. Cluster locations using appropriate distance metrics\n",
    "4. Build and evaluate cluster-specific models\n",
    "\n",
    "**Note to UST Faculty**: Typically we would connect to GBQ for the data, but to ensure access the data can be reached via [this link](https://www.dropbox.com/t/H5lPzrmt29Oq1F5V). Download this zip and extract the contents into a folder called `data/` within the repository. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Boilerplate\n",
    "\n",
    "#### Purpose of Exercises\n",
    "Exercises are a critical part of this class. While lectures and readings introduce concepts, exercises help you:\n",
    "- Develop practical implementation skills\n",
    "- Understand common pitfalls and debugging strategies\n",
    "- Build intuition through experimentation\n",
    "- Create a portfolio of working examples\n",
    "- Practice real-world data analysis workflows\n",
    "\n",
    "#### Using These Notebooks\n",
    "- **Dive Right In**: These exercises often reveal unexpected challenges\n",
    "- **Work Incrementally**: Test each step before moving forward\n",
    "- **Ask Questions**: Use class Teams for help, ask your instructor, ask classmates\n",
    "- **Compare Solutions**: Solutions are available to you in this folder\n",
    "- **Save Your Work**: Commit working versions to your repository\n",
    "\n",
    "#### Using AI Assistants\n",
    "AI coding assistants (ChatGPT, Claude, GitHub Copilot, etc.) are powerful tools that you'll use in your career. In this class:\n",
    "- ✅ Use AI to understand code snippets\n",
    "- ✅ Use AI to debug errors\n",
    "- ✅ Use AI to explore alternative approaches\n",
    "- ✅ Use AI to explain concepts\n",
    "- ❌ Don't just paste the whole exercise\n",
    "- ❌ Don't submit AI-generated code without understanding it\n",
    "\n",
    "Document your AI interactions in a comment block and include a link to your chat:\n",
    "```python\n",
    "# AI Interaction Log:\n",
    "# 1. Asked Claude to explain the difference between train_test_split and TimeSeriesSplit\n",
    "# 2. Used GitHub Copilot to help write data validation functions\n",
    "# 3. Had ChatGPT debug a pandas groupby error\n",
    "# 4. Chat logs are available here: https://chatgpt.com/c/671d1f08-1ebc-8011-a128-8a29255f24fe\n",
    "```\n",
    "\n",
    "#### Evaluation\n",
    "Exercises are not evaluated by your instructor. They are for your learning.\n",
    "\n",
    "### Setup\n",
    "First, we'll load our required libraries and prepare our data sources. We need libraries for data manipulation, clustering, modeling, and visualization.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling & clustering\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import gower\n",
    "\n",
    "# Display utilities\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "We'll reuse some functions from our previous exercise and add clustering-specific functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentials from previous notebook\n",
    "def load_data():\n",
    "    \"\"\"Load car listing data and market summaries\"\"\"\n",
    "    listing_data = pd.read_csv('../data/processed_listing_pages.csv')\n",
    "    listing_data['age'] = 2024 - listing_data['year']\n",
    "    \n",
    "    # Load location summary data\n",
    "    loc_data = pd.read_csv('../data/location_summary_data.csv')\n",
    "    return listing_data, loc_data\n",
    "\n",
    "def get_features(data):\n",
    "    \"\"\"Create feature matrix for modeling\"\"\"\n",
    "    # TODO\n",
    "    pass\n",
    "\n",
    "def filter_data(data, make, model, location=None):\n",
    "    \"\"\"Filter data for specific make/model and optional location\"\"\"\n",
    "    mask = (data['make'] == make) & (data['model'] == model)\n",
    "    if location:\n",
    "        mask = mask & (data['location'] == location)\n",
    "    return data[mask].copy()\n",
    "\n",
    "def create_model(X, y):\n",
    "    \"\"\"Create and fit a linear regression model\"\"\"\n",
    "    # TODO\n",
    "    pass\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    \"\"\"Calculate model performance metrics\"\"\"\n",
    "    # TODO\n",
    "    pass\n",
    "\n",
    "\n",
    "# TODO: Create a function to compare markets\n",
    "def compare_markets(loc_data, markets_to_compare):\n",
    "    \"\"\"Compare key statistics across different markets\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    loc_data: DataFrame with market data\n",
    "    markets_to_compare: list of market names to compare\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with market comparisons\n",
    "    \"\"\"\n",
    "    pass  # Your code here\n",
    "    \n",
    "# TODO: Create a function to prepare data for clustering\n",
    "def prepare_cluster_data(loc_data):\n",
    "    \"\"\"Prepare location data for clustering\n",
    "    \n",
    "    Consider:\n",
    "    - Which numeric features to include?\n",
    "    - How to handle categorical data?\n",
    "    - Should we scale the data?\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame ready for clustering\n",
    "    \"\"\"\n",
    "    pass  # Your code here\n",
    "\n",
    "# Helper for naming clusters\n",
    "def create_cluster_names(loc_data):\n",
    "    \"\"\"Create descriptive names for each market cluster\n",
    "    combining region and dominant state\"\"\"\n",
    "    names = loc_data.groupby('cluster').agg({\n",
    "        'census_region': lambda x: x.mode()[0],\n",
    "        'state': lambda x: x.mode()[0]\n",
    "    }).apply(lambda x: f\"{x.name}-{x['census_region']}-{x['state']}\", axis=1)\n",
    "    return names\n",
    "\n",
    "def build_cluster_model(data, needed_obvs=50):\n",
    "    \"\"\"Build model for a cluster if enough data exists\"\"\"\n",
    "    if len(data) < needed_obvs:\n",
    "        return {\n",
    "            'n_obs': len(data),\n",
    "            'rmse': np.nan,\n",
    "            'mae': np.nan,\n",
    "            'r2': np.nan,\n",
    "            'price': np.mean(data['price'])\n",
    "        }\n",
    "    \n",
    "    # TODO: Implement model building, return metrics\n",
    "    #metrics = evaluate_model(model, X, y)\n",
    "    #metrics['n_obs'] = len(data)\n",
    "    #metrics['price'] = np.mean(y)\n",
    "    \n",
    "    return None #TODO: metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Explore Market Data\n",
    "First, we'll load our market data and look at the characteristics that might make markets similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load location summaries and listing data\n",
    "listing_data, loc_data = load_data() \n",
    "\n",
    "# TODO: Explore what makes markets similar\n",
    "# Look at a few example markets to understand what features we have\n",
    "example_markets = ['seattle', 'newyork', 'houston']\n",
    "market_comparison = loc_data[loc_data['location'].isin(example_markets)]\n",
    "display(market_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Choose features for clustering\n",
    "# Consider:\n",
    "# 1. Basic market statistics (listings, prices, ages)\n",
    "# 2. Geographic information\n",
    "# 3. Car-specific features (F150 prices vs Civic prices)\n",
    "\n",
    "# Print the columns we have available\n",
    "print(\"\\nAvailable features:\")\n",
    "for col in loc_data.columns:\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "# TODO: Examine distributions of key features\n",
    "# HINT: Consider using sns.distplot or plt.hist\n",
    "# Which features might need scaling?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Prepare data for clustering\n",
    "# 1. Select relevant features\n",
    "# 2. Handle categorical variables\n",
    "# 3. Consider scaling numeric features\n",
    "\n",
    "# Example of handling categorical variables:\n",
    "market_features = loc_data.drop('location', axis=1)\n",
    "market_features['state'] = pd.Categorical(market_features['state']).codes\n",
    "market_features['census_region'] = pd.Categorical(market_features['census_region']).codes\n",
    "\n",
    "# Extension: Try different feature combinations\n",
    "# How do they affect your clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Clustering\n",
    "We'll use k-means clustering with k=8 based on our market exploration. This gives us reasonable market sizes while maintaining geographic coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Prepare data for clustering\n",
    "# First we need to separate numeric and categorical columns\n",
    "cat_cols = ['state', 'census_region']\n",
    "# TODO: What other columns should we use for clustering?\n",
    "# HINT: Look at loc_data.columns and think about what makes markets similar\n",
    "num_cols = [col for col in loc_data.columns \n",
    "            if col not in cat_cols + ['location']]\n",
    "\n",
    "# Print what we're using\n",
    "print(\"Features for clustering:\")\n",
    "print(\"Categorical:\", cat_cols)\n",
    "print(\"Numeric:\", num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Handle missing values\n",
    "# First, let's see what we're dealing with\n",
    "print(\"\\nMissing values by column:\")\n",
    "print(cluster_features.isna().sum()[cluster_features.isna().sum() > 0])\n",
    "\n",
    "# TODO: Choose a strategy for missing values\n",
    "# 1. Remove columns with too many missing values?\n",
    "# 2. Fill with mean/median?\n",
    "# 3. Something else?\n",
    "\n",
    "# Here's one approach - is it the best one?\n",
    "cluster_features = loc_data[num_cols + cat_cols].copy()\n",
    "cluster_features[num_cols] = cluster_features[num_cols].fillna(\n",
    "    cluster_features[num_cols].mean()\n",
    ")\n",
    "\n",
    "# Calculate distance matrix using Gower distance\n",
    "# This handles mixed numeric/categorical data\n",
    "gower_dist = gower.gower_matrix(cluster_features)\n",
    "\n",
    "# TODO: Examine the distances\n",
    "# 1. What's the range of distances?\n",
    "# 2. Which markets are most similar?\n",
    "# 3. Which are most different?\n",
    "\n",
    "print(\"\\nDistance matrix shape:\", gower_dist.shape)\n",
    "print(\"Distance range:\", np.min(gower_dist), \"to\", np.max(gower_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PAM/KMedoids on the distance matrix\n",
    "k = None # TODO: Choose a number of clusters\n",
    "pam = KMedoids(n_clusters=k, random_state=42, metric='precomputed')\n",
    "market_clusters = pam.fit_predict(gower_dist)\n",
    "\n",
    "# Add clusters back to location data\n",
    "loc_data['cluster'] = market_clusters\n",
    "\n",
    "# See cluster sizes and characteristics\n",
    "print(\"\\nCluster Sizes:\")\n",
    "print(pd.Series(market_clusters).value_counts().sort_index())\n",
    "\n",
    "# Examine cluster characteristics\n",
    "cluster_summary = loc_data.groupby('cluster').agg({\n",
    "    'total_listings': 'mean',\n",
    "    'avg_price': 'mean',\n",
    "    'census_region': lambda x: x.mode()[0],\n",
    "    'state': lambda x: x.mode()[0]\n",
    "}).round(2)\n",
    "\n",
    "display(cluster_summary)\n",
    "\n",
    "# Optional: Look at most similar markets to a specific market\n",
    "example_market = 'seattle'\n",
    "market_idx = loc_data[loc_data['location'] == example_market].index[0]\n",
    "distances = gower_dist[market_idx]\n",
    "similar_idx = np.argsort(distances)[:5]  # Get 5 most similar\n",
    "similar_markets = loc_data.iloc[similar_idx]\n",
    "print(f\"\\nMarkets most similar to {example_market}:\")\n",
    "display(similar_markets[['location', 'cluster', 'total_listings', 'avg_price']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Make/Model and Build Models\n",
    "Now we'll select a popular make/model combination and compare national vs cluster-specific models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select make/model and merge cluster assignments\n",
    "make = None # TODO: Choose a make\n",
    "model_name = None # TODO: Choose a model\n",
    "\n",
    "mm_data = filter_data(listing_data, make, model_name)\n",
    "mm_data = mm_data.merge(loc_data[['location', 'cluster']], on='location', how='left')\n",
    "\n",
    "print(f\"Total {make} {model_name} listings: {len(mm_data)}\")\n",
    "print(\"\\nListings per cluster:\")\n",
    "display(mm_data.groupby('cluster')['price'].count().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Compare Models\n",
    "Now that we have our market clusters, let's:\n",
    "1. Build a national model for our chosen make/model\n",
    "2. Build separate models for each cluster\n",
    "3. Compare the performance across approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build national model\n",
    "# TODO: Create a function to build a model for a specific cluster\n",
    "\n",
    "# Build cluster models and evaluate\n",
    "cluster_results = []\n",
    "for cluster_id in range(k):\n",
    "    # TODO - build model for each cluster\n",
    "    cluster_data = mm_data[mm_data['cluster'] == cluster_id]\n",
    "    metrics = build_cluster_model(cluster_data, needed_obvs=50)\n",
    "    metrics['cluster'] = cluster_id\n",
    "    cluster_results.append(metrics)\n",
    "\n",
    "cluster_results = pd.DataFrame(cluster_results)\n",
    "\n",
    "# Calculate summary statistics\n",
    "n_markets_with_models = sum(~cluster_results['rmse'].isna())\n",
    "total_coverage = cluster_results['n_obs'].sum() / len(mm_data)\n",
    "avg_improvement = ((national_metrics['rmse'] - cluster_results['rmse'].mean()) \n",
    "                  / national_metrics['rmse'] * 100)\n",
    "\n",
    "print(f\"Coverage Statistics:\")\n",
    "print(f\"Markets with models: {n_markets_with_models} of {k}\")\n",
    "print(f\"Total coverage: {total_coverage:.1%}\")\n",
    "print(f\"Average RMSE improvement: {avg_improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results\n",
    "Let's create some visualizations to understand our clusters and their performance.\n",
    "\n",
    "I've left these for you here to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cluster name mapping\n",
    "cluster_names = loc_data.groupby('cluster').agg({\n",
    "    'census_region': lambda x: x.mode()[0],\n",
    "    'state': lambda x: x.mode()[0]\n",
    "}).apply(lambda x: f\"{x.name}-{x['census_region']}-{x['state']}\", axis=1)\n",
    "\n",
    "# Plot average prices by cluster\n",
    "plt.figure(figsize=(12, 6))\n",
    "cluster_results['avg_price'] = cluster_results['price']  # from build_cluster_model\n",
    "plot_data = cluster_results.sort_values('avg_price', ascending=True)\n",
    "plt.barh(range(len(plot_data)), plot_data['avg_price'])\n",
    "plt.yticks(range(len(plot_data)), \n",
    "          [cluster_names[i] for i in plot_data['cluster']])\n",
    "plt.xlabel('Average Price')\n",
    "plt.title(f'Average {make.title()} {model_name.upper()} Price by Market Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot RMSE improvement\n",
    "plt.figure(figsize=(12, 6))\n",
    "improvement = (national_metrics['rmse'] - cluster_results['rmse']) / national_metrics['rmse'] * 100\n",
    "plot_data = cluster_results.assign(improvement=improvement).sort_values('improvement')\n",
    "plt.barh(range(len(plot_data)), plot_data['improvement'])\n",
    "plt.yticks(range(len(plot_data)), \n",
    "          [cluster_names[i] for i in plot_data['cluster']])\n",
    "plt.axvline(x=0, color='red', linestyle='--')\n",
    "plt.xlabel('RMSE Improvement (%)')\n",
    "plt.title('Model Improvement by Cluster vs National Model')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
